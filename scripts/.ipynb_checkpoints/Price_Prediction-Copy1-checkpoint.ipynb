{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('listings_v1.1.xlsx', skiprows=4)\n",
    "df1 = df.dropna(subset=['review_scores_rating'])\n",
    "df1 = df1.drop(['weekly_price', 'security_deposit', 'cleaning_fee', 'extra_people'], axis=1)\n",
    "df2 = df[df['review_scores_rating'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\27425\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\27425\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill mean value:\n",
    "\n",
    "lists = ['review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'reviews_per_month', 'host_response_rate']\n",
    "\n",
    "df1 = df1.fillna({'review_scores_rating': 100})\n",
    "\n",
    "for ele in lists:\n",
    "    df1[ele].fillna(df1[ele].mean(), axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all the text to lower case\n",
    "df1 = df1.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('room', 1708), ('boston', 1578), ('apartment', 1281), ('bed', 1274), ('kitchen', 1223), ('bedroom', 1147), ('living', 911), ('floor', 792), ('one', 772), ('two', 771)]\n",
      "[('line', 1646), ('walk', 1628), ('boston', 1353), ('station', 1327), ('minutes', 1075), ('bus', 1000), ('minute', 924), ('nan', 858), ('street', 837), ('parking', 703)]\n",
      "[('nan', 1025), ('available', 689), ('guests', 447), ('phone', 398), ('stay', 387), ('questions', 366), ('need', 309), ('help', 301), ('email', 291), ('happy', 241)]\n",
      "[('internet', 4729), ('detector', 4297), ('tv', 3423), ('dryer', 3283), ('friendly', 2836), ('wireless', 2645), ('heating', 2617), ('kitchen', 2523), ('smoke', 2322), ('essentials', 2290)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('internet', 4729),\n",
       " ('detector', 4297),\n",
       " ('tv', 3423),\n",
       " ('dryer', 3283),\n",
       " ('friendly', 2836),\n",
       " ('wireless', 2645),\n",
       " ('heating', 2617),\n",
       " ('kitchen', 2523),\n",
       " ('smoke', 2322),\n",
       " ('essentials', 2290)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    for cols in text:\n",
    "        tokens = nltk.word_tokenize(df1[cols].str.cat(sep=' '))\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        \n",
    "        # Remove stop words\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        additional = set([\"''\" , ',' ,'{' ,'}','.',':',';','(',')','[',']','!','?','``','--','&','@','#','$','%','^','*','_','+','-','/','|','~','`','\"','\\'','\\\\','1','2','3','4','5','6','7','8','9','0'])\n",
    "        stop_words.update(additional)\n",
    "        \n",
    "        filtered_tokens = [word for word in tokens if not word.lower() in stop_words]\n",
    "        # Extract keywords based on frequency\n",
    "        word_freq = Counter(filtered_tokens)\n",
    "        top10_keywords = word_freq.most_common(10)\n",
    "        print(top10_keywords)\n",
    "        return top10_keywords\n",
    "\n",
    "tokens_house = ['space', 'description', 'neighborhood_overview']\n",
    "tokens_trans = ['transit', 'access']\n",
    "tokens_host = ['interaction','host_about']\n",
    "tokens_amenties = ['amenities']\n",
    "\n",
    "tokenize(tokens_house)\n",
    "tokenize(tokens_trans)\n",
    "tokenize(tokens_host)\n",
    "tokenize(tokens_amenties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical variables for the top keywords\n",
    "house_keywords = ['room', 'bedroom', 'bed', 'kitchen', 'bathroom', 'living', 'floor']\n",
    "trans_keywords = ['bus', 'line', 'walk', 'station', 'minutes', 'minute', 'street','parking','downtown']\n",
    "host_keywords = ['host', 'guests', 'help', 'available', 'phone', 'questions', 'email']\n",
    "amenties_keywords = ['internet', 'detector', 'tv', 'dryer', 'wireless', 'heating', 'kitchen', 'smoke', 'essentials']\n",
    "\n",
    "for keyword in amenties_keywords:\n",
    "    df1[keyword] = df1['amenities'].str.contains(keyword).astype(int)\n",
    "\n",
    "for keyword in host_keywords:\n",
    "    for cols in tokens_host:\n",
    "        df1[keyword] = df1[cols].str.contains(keyword).astype(int)\n",
    "\n",
    "for keyword in house_keywords:\n",
    "    for cols in tokens_house:\n",
    "        df1[keyword] = df1[cols].str.contains(keyword).astype(int)\n",
    "\n",
    "for keyword in trans_keywords:\n",
    "    for cols in tokens_trans:\n",
    "        df1[keyword] = df1[cols].str.contains(keyword).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the columns in tokens_house, tokens_trans, tokens_host, tokens_amenties\n",
    "columns_to_delete = tokens_house + tokens_trans + tokens_host + tokens_amenties\n",
    "\n",
    "# drop the columns\n",
    "df1 = df1.drop(columns_to_delete, axis=1)\n",
    "df1 = df1.drop(['id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns into numerical values and fill missing values with mean\n",
    "obj_columns = ['host_response_rate',\n",
    " 'host_acceptance_rate',\n",
    " 'host_is_superhost',\n",
    " 'host_listings_count',\n",
    " 'host_total_listings_count',\n",
    " 'host_has_profile_pic',\n",
    " 'host_identity_verified',\n",
    " 'accommodates',\n",
    " 'bathrooms',\n",
    " 'bedrooms',\n",
    " 'beds',\n",
    " 'square_feet',\n",
    " 'price',\n",
    " 'minimum_nights',\n",
    " 'maximum_nights',\n",
    " 'availability_30',\n",
    " 'availability_60',\n",
    " 'availability_90',\n",
    " 'availability_365',\n",
    " 'number_of_reviews',\n",
    " 'reviews_per_month',\n",
    " 'review_duration',\n",
    " 'review_time',\n",
    " 'review_scores_rating',\n",
    " 'review_scores_accuracy',\n",
    " 'review_scores_cleanliness',\n",
    " 'review_scores_checkin',\n",
    " 'review_scores_communication',\n",
    " 'review_scores_location',\n",
    " 'review_scores_value',\n",
    " 'instant_bookable']\n",
    "\n",
    "for col in obj_columns:\n",
    "    if df1[col].dtype == 'object':\n",
    "        df1[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Fill missing values with mean\n",
    "for col in obj_columns:\n",
    "    if df1[col].isnull().any():\n",
    "        mean_val = df1[col].mean()\n",
    "        df1[col].fillna(mean_val, inplace=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object columns to categorical\n",
    "obj_columns = df1.select_dtypes(include=['object']).columns\n",
    "\n",
    "# one-hot encode object columns\n",
    "df1 = pd.get_dummies(df1, columns=obj_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Linear Regression:  0.3715080301212883\n",
      "Accuracy score for Random Forest:  0.653263438462211\n"
     ]
    }
   ],
   "source": [
    "# Conduct RFE using Linear Regression, Random Forest, SVM\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1.drop('price', axis=1), df1['price'], test_size=0.2, random_state=42)\n",
    "\n",
    "rfe_lr = RFE(LinearRegression(), n_features_to_select=20)\n",
    "rfe_rf = RFE(RandomForestRegressor(), n_features_to_select=20)\n",
    "\n",
    "rfe_lr.fit(X_train, y_train)\n",
    "rfe_rf.fit(X_train, y_train)\n",
    "\n",
    "Y_predict_lr = rfe_lr.predict(X_test)\n",
    "Y_predict_rf = rfe_rf.predict(X_test)\n",
    "\n",
    "score_lr = rfe_lr.score(X_test, y_test)\n",
    "score_rf = rfe_rf.score(X_test, y_test)\n",
    "\n",
    "print('Accuracy score for Linear Regression: ', score_lr)\n",
    "print('Accuracy score for Random Forest: ', score_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Features  Importance\n",
      "19  room_type_entire home/apt    0.220963\n",
      "6                    bedrooms    0.178206\n",
      "5                   bathrooms    0.155674\n",
      "16                review_time    0.044854\n",
      "12           availability_365    0.039611\n",
      "14          reviews_per_month    0.038022\n",
      "8              minimum_nights    0.034956\n",
      "15            review_duration    0.033941\n",
      "10            availability_60    0.032359\n",
      "4                accommodates    0.024221\n",
      "7                        beds    0.023792\n",
      "11            availability_90    0.023755\n",
      "13          number_of_reviews    0.023449\n",
      "17       review_scores_rating    0.022361\n",
      "1        host_acceptance_rate    0.022346\n",
      "18     review_scores_location    0.020012\n",
      "9             availability_30    0.018202\n",
      "0          host_response_rate    0.015571\n",
      "3   host_total_listings_count    0.014328\n",
      "2         host_listings_count    0.013379\n"
     ]
    }
   ],
   "source": [
    "# Get the features selected by RFE on Random Forest\n",
    "feature_name = X_train.columns[rfe_rf.support_]\n",
    "feature_importance = rfe_rf.estimator_.feature_importances_\n",
    "\n",
    "features = pd.DataFrame({'Features': feature_name, 'Importance': feature_importance})\n",
    "print(features.sort_values(by='Importance', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
