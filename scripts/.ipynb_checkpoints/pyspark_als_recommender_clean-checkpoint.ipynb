{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4e1c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql import Row\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110e5ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 16:55:49 WARN Utils: Your hostname, Yashnas-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.31.9.97 instead (on interface en0)\n",
      "23/04/07 16:55:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Users/yashnagogineni/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/yashnagogineni/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/yashnagogineni/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b96d7a88-fba7-4e4d-98fb-82bba8d63ec8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;3.0.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.0.5 in central\n",
      "\tfound org.mongodb#bson;4.0.5 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.0.5 in central\n",
      ":: resolution report :: resolve 103ms :: artifacts dl 4ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.0.5 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.0.5 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;3.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   0   ||   4   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b96d7a88-fba7-4e4d-98fb-82bba8d63ec8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 4 already retrieved (0kB/3ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 16:55:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 16:55:50 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"mongodbtest1\") \\\n",
    ".master('local')\\\n",
    ".config(\"spark.mongodb.input.uri\", \"mongodb://localhost:27017/bdata.scored_reviews_bart\") \\\n",
    ".config(\"spark.mongodb.output.uri\", \"mongodb://localhost:27017/bdata.scored_reviews_bart\") \\\n",
    ".config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e257768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = spark.read\\\n",
    ".format('com.mongodb.spark.sql.DefaultSource')\\\n",
    ".option( \"uri\", \"mongodb://localhost:27017/bdata.scored_reviews_bart\") \\\n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b31716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+--------------------+----------+-------+--------------------+--------+----------+---------------------+------------+-----------+-------------+--------------------+\n",
      "|                 _id|cmnt_length|            comments|      date|     id|              labels|language|listing_id|preprocessed_comments|rating_score|reviewer_id|reviewer_name|              scores|\n",
      "+--------------------+-----------+--------------------+----------+-------+--------------------+--------+----------+---------------------+------------+-----------+-------------+--------------------+\n",
      "|{642fd6caecfdd4a1...|        249|My stay at islam'...|2013-05-21|4724140|['positive', 'neg...|      en|   1178162| my stay at islams...|         5.0|    4298113|      Olivier|[0.99642163515090...|\n",
      "|{642fd6caecfdd4a1...|        411|The place is real...|2013-09-28|7646702|['positive', 'neg...|      en|   1178162| the place is real...|         5.0|    8197342|    Arkadiusz|[0.99575150012969...|\n",
      "|{642fd6caecfdd4a1...|        387|Our stay at Islam...|2013-10-15|8094418|['positive', 'neg...|      en|   1178162| our stay at islam...|         5.0|    9040491|      Matthew|[0.99736118316650...|\n",
      "|{642fd6caecfdd4a1...|        389|Our stay at Islam...|2013-10-19|8174594|['positive', 'neg...|      en|   1178162| our stay at islam...|         5.0|    9101576|       Simona|[0.99751394987106...|\n",
      "|{642fd6caecfdd4a1...|        445|We really enjoyed...|2013-06-06|5003196|['positive', 'neg...|      en|   1178162| we really enjoyed...|         5.0|    6449554|    Sebastian|[0.99587970972061...|\n",
      "+--------------------+-----------+--------------------+----------+-------+--------------------+--------+----------+---------------------+------------+-----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "230ed798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select column in loaded \n",
    "reviews1 = reviews.select(['listing_id', 'reviewer_id', 'rating_score'])\n",
    "# cast column datatype as float\n",
    "reviews1 = reviews1.withColumn('listing_id', col('listing_id').cast(FloatType()))\n",
    "reviews1 = reviews1.withColumn('reviewer_id', col('reviewer_id').cast(FloatType()))\n",
    "reviews1 = reviews1.withColumn('rating_score', col('rating_score').cast(FloatType()))\n",
    "\n",
    "\n",
    "# filter null values listing id\n",
    "reviews1 = reviews1.where(reviews1.listing_id.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa67f32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+\n",
      "|listing_id|reviewer_id|rating_score|\n",
      "+----------+-----------+------------+\n",
      "|         0|          0|           0|\n",
      "+----------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get null value counts\n",
    "reviews1.select([count(when(isnan(c), c)).alias(c) for c in reviews1.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10a6ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of ratings for each user\n",
    "user_counts = reviews1.groupBy(\"reviewer_id\").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "# Filter the users with more than 1 rating\n",
    "filtered_users = user_counts.filter(\"count > 1\")\n",
    "\n",
    "# Get the user IDs as a list\n",
    "user_ids = filtered_users.select(\"reviewer_id\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "681cd715",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews2 = reviews1.filter(col(\"reviewer_id\").isin(user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e245131c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaWrapper.__del__ at 0x7fca2aa11160>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yashnagogineni/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/wrapper.py\", line 53, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'ALS' object has no attribute '_java_obj'\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "reviews = reviews1.select('rating_score').collect()\n",
    "review_list = [reviews[i][0] for i in range(len(reviews))]\n",
    "\n",
    "plt.hist(review_list, bins=[0.5,1.5,2.5,3.5,4.5,5.5], alpha=0.5,\n",
    "         histtype='stepfilled', color='steelblue',\n",
    "         edgecolor='none')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Rating')\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3319fe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "train_data, test_data = reviews1.randomSplit([0.8, 0.2], seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4712662a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51466, 12925)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get no of records in training data\n",
    "train_data.count(), test_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b56b276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    rank=5,\n",
    "    maxIter=40, # updated parameters based on the hyperparameter values\n",
    "    regParam=0.2,\n",
    "    userCol=\"reviewer_id\",\n",
    "    itemCol=\"listing_id\",\n",
    "    ratingCol=\"rating_score\",\n",
    "    coldStartStrategy=\"drop\",implicitPrefs=False,\n",
    "    nonnegative=True\n",
    ")\n",
    "\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                            labelCol=\"rating_score\",\n",
    "                            predictionCol=\"prediction\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec4942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning of model\n",
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als.rank,[5,10,20,30])\\\n",
    "    .addGrid(als.regParam,[ 0.01, 0.1, 0.05,0.2])\\\n",
    "    .addGrid(als.maxIter,[10,20,30,40])\\\n",
    "    .build()\n",
    "\n",
    "\n",
    "# cross validation on training data\n",
    "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=5)\n",
    "# create model based on cv \n",
    "model = cv.fit(train_data)\n",
    "\n",
    "best_rank = model.bestModel.rank\n",
    "best_regparam = model.bestModel._java_obj.parent().getRegParam()\n",
    "best_maxiter = model.bestModel._java_obj.parent().getMaxIter()\n",
    "print(f'Rank : {best_rank}, Regparam: {best_regparam}, Maxiter: {best_maxiter}')\n",
    "\n",
    "# Generate predictions on the test data\n",
    "predictions = model.bestModel.transform(test_data)\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Rmse on Test set',rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "509976b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rmse on Test set 0.3805730071662779\n",
      "Rmse on Test set 1.397873639165796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 59262:================================>                     (6 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = als.fit(train_data)\n",
    "# Generate predictions on the test data\n",
    "train_predictions = model.transform(train_data)\n",
    "train_rmse = evaluator.evaluate(train_predictions)\n",
    "print('Rmse on Test set',train_rmse)\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print('Rmse on Test set',rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a0d09d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_recs = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7959b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(listing_id=8814479, rating=5.053880214691162),\n",
       " Row(listing_id=8271384, rating=4.831165790557861),\n",
       " Row(listing_id=1724900, rating=4.826288223266602),\n",
       " Row(listing_id=7214920, rating=4.825158596038818),\n",
       " Row(listing_id=3420384, rating=4.820468425750732),\n",
       " Row(listing_id=10106081, rating=4.818856239318848),\n",
       " Row(listing_id=13733558, rating=4.818426132202148),\n",
       " Row(listing_id=4160585, rating=4.814695835113525),\n",
       " Row(listing_id=6870366, rating=4.810781002044678),\n",
       " Row(listing_id=7367795, rating=4.808238506317139)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_recs.collect()[0]['recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bdd94224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import Evaluator\n",
    "from pyspark.sql.functions import col, expr\n",
    "\n",
    "class MPREvaluator(Evaluator):\n",
    "    \n",
    "    def __init__(self, rating_col='rating_score', prediction_col='prediction', threshold=4):\n",
    "        self.rating_col = rating_col\n",
    "        self.prediction_col = prediction_col\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def _evaluate(self, dataset):\n",
    "        tp = dataset.filter(col(self.rating_col) >= self.threshold).count()\n",
    "        fp = dataset.filter(col(self.rating_col) < self.threshold).count()\n",
    "        fn = dataset.filter(col(self.prediction_col) >= self.threshold).count()\n",
    "        precision = tp / (tp + fp + fn)\n",
    "        return 1 - precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "564d594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4134748500230734"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_evaluator = MPREvaluator(rating_col='rating_score', prediction_col='prediction', threshold=4)\n",
    "\n",
    "mp_evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c11c555",
   "metadata": {},
   "source": [
    "Delete the below code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd9ed1b",
   "metadata": {},
   "source": [
    "### KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "29b4436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, Normalizer, VectorSizeHint\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "\n",
    "# Prepare data\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"reviewer_id\", \"listing_id\"], \n",
    "                                  outputCol=\"features\")\n",
    "\n",
    "normalizer = Normalizer(inputCol=\"features\", \n",
    "                        outputCol=\"normalized_features\")\n",
    "\n",
    "als = ALS(rank=20, maxIter=30, regParam=0.1, userCol=\"reviewer_id\", itemCol=\"listing_id\", ratingCol=\"rating\", coldStartStrategy=\"drop\")\n",
    "train_df = vectorAssembler.transform(train_data)\n",
    "train_df = normalizer.transform(train_df)\n",
    "model = als.fit(train_df)\n",
    "\n",
    "# Transform data\n",
    "user_factors = model.userFactors\n",
    "item_factors = model.itemFactors\n",
    "\n",
    "# renaming the column name\n",
    "user_factors = user_factors.selectExpr(\"id as reviewer_id\", \"features as user_features\")\n",
    "item_factors = item_factors.selectExpr(\"id as listing_id\", \"features as item_features\")\n",
    "\n",
    "# merging the vector with previous dataframe\n",
    "train_df = train_df.join(user_factors, \"reviewer_id\", \"left\")\n",
    "train_df = train_df.join(item_factors, \"listing_id\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45536a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------+--------+-------------------+-------------+-------------+\n",
      "|listing_id|reviewer_id|rating|features|normalized_features|user_features|item_features|\n",
      "+----------+-----------+------+--------+-------------------+-------------+-------------+\n",
      "|         0|          0|     0|       0|                  0|            0|            0|\n",
      "+----------+-----------+------+--------+-------------------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# count null values in each column\n",
    "null_counts = train_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in train_df.columns])\n",
    "\n",
    "# show results\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d51ec39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------+----------------+--------------------+--------------------+--------------------+\n",
      "|listing_id|reviewer_id|rating|        features| normalized_features|       user_features|       item_features|\n",
      "+----------+-----------+------+----------------+--------------------+--------------------+--------------------+\n",
      "|    3353.0|    12970.0|   5.0|[12970.0,3353.0]|[0.96817061791272...|[-0.33091545, 0.1...|[-0.37797898, 0.1...|\n",
      "+----------+-----------+------+----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 133311:===============================>                     (6 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3eb1eccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create userfeatures vector from als algorithm\n",
    "test_df = vectorAssembler.transform(test_data)\n",
    "test_df = normalizer.transform(test_df)\n",
    "\n",
    "\n",
    "user_test = model.transform(test_df).select(\"listing_id\", \"features\")\n",
    "# renaming the column name\n",
    "test_user_factors = user_test.selectExpr(\"listing_id\", \"features as item_features\")\n",
    "# merge feature with test set\n",
    "test_df = test_df.join(test_user_factors, \"listing_id\", \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "12e7a6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------+------------------+--------------------+-------------+\n",
      "|listing_id|reviewer_id|rating|          features| normalized_features|item_features|\n",
      "+----------+-----------+------+------------------+--------------------+-------------+\n",
      "|    9857.0|  3312378.0|   5.0|[3312378.0,9857.0]|[0.99999557231363...|         null|\n",
      "+----------+-----------+------+------------------+--------------------+-------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "76e59fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Bucketed Random Projection LSH model\n",
    "vectorSizeHint = VectorSizeHint(inputCol=\"user_features\", size=20, handleInvalid=\"skip\")\n",
    "assembler = VectorAssembler(inputCols=[\"user_features\"], outputCol=\"user_features_new\")\n",
    "brp = BucketedRandomProjectionLSH(inputCol=\"features\", \n",
    "                                  outputCol=\"hashes\", numHashTables=3, \n",
    "                                  bucketLength=0.1)\n",
    "\n",
    "\n",
    "brp_model = brp.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b9484643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 135290:===============>                                     (3 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+--------+-------------------+-------------+\n",
      "|reviewer_id|listing_id|rating|features|normalized_features|user_features|\n",
      "+-----------+----------+------+--------+-------------------+-------------+\n",
      "|          0|         0|     0|       0|                  0|         1406|\n",
      "+-----------+----------+------+--------+-------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# count null values in each column\n",
    "null_counts = test_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in test_df.columns])\n",
    "\n",
    "# show results\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d9c7c295",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = [row.reviewer_id for row in train_df.select('reviewer_id').distinct().collect()]\n",
    "\n",
    "filtered_test_df = test_df.filter(col(\"reviewer_id\").isin(fs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cd5c8b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6156719e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 135650:===============================>                     (6 + 1) / 10]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1448"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "927f2adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o147746.approxNearestNeighbors. Trace:\npy4j.Py4JException: Method approxNearestNeighbors([class org.apache.spark.sql.Dataset, class java.lang.String, class java.lang.Integer, class java.lang.String]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [177]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m knn_df \u001b[38;5;241m=\u001b[39m \u001b[43mbrp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapproxNearestNeighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/feature.py:423\u001b[0m, in \u001b[0;36m_LSHModel.approxNearestNeighbors\u001b[0;34m(self, dataset, key, numNearestNeighbors, distCol)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapproxNearestNeighbors\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     dataset: DataFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m     distCol: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistCol\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    394\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    395\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    Given a large dataset and an item, approximately find at most k items which have the\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    closest distance to the item. If the :py:attr:`outputCol` is missing, the method will\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m        added to show the distance between each row and the key.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_java\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapproxNearestNeighbors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumNearestNeighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistCol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/wrapper.py:72\u001b[0m, in \u001b[0;36mJavaWrapper._call_java\u001b[0;34m(self, name, *args)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m sc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m java_args \u001b[38;5;241m=\u001b[39m [_py2java(sc, arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _java2py(sc, \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mjava_args\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py:330\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m             \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name))\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o147746.approxNearestNeighbors. Trace:\npy4j.Py4JException: Method approxNearestNeighbors([class org.apache.spark.sql.Dataset, class java.lang.String, class java.lang.Integer, class java.lang.String]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:1623)\n\n"
     ]
    }
   ],
   "source": [
    "knn_df = brp_model.approxNearestNeighbors(test_df, \"user_features\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8715525a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "requirement failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [133]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m assembler \u001b[38;5;241m=\u001b[39m VectorAssembler(inputCols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_features\u001b[39m\u001b[38;5;124m\"\u001b[39m], outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m brp \u001b[38;5;241m=\u001b[39m BucketedRandomProjectionLSH(inputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     31\u001b[0m                                   outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhashes\u001b[39m\u001b[38;5;124m\"\u001b[39m, numHashTables\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \n\u001b[1;32m     32\u001b[0m                                   bucketLength\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mvectorSizeHint\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m train_df \u001b[38;5;241m=\u001b[39m assembler\u001b[38;5;241m.\u001b[39mtransform(train_df)\n\u001b[1;32m     37\u001b[0m brp_model \u001b[38;5;241m=\u001b[39m brp\u001b[38;5;241m.\u001b[39mfit(train_df)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/ml/wrapper.py:400\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: requirement failed"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fit Bucketed Random Projection LSH model\n",
    "vectorSizeHint = VectorSizeHint(inputCol=\"user_features\", size=20, handleInvalid=\"skip\")\n",
    "assembler = VectorAssembler(inputCols=[\"user_features\"], outputCol=\"user_features\")\n",
    "brp = BucketedRandomProjectionLSH(inputCol=\"features\", \n",
    "                                  outputCol=\"hashes\", numHashTables=3, \n",
    "                                  bucketLength=0.1)\n",
    "\n",
    "train_df = vectorSizeHint.transform(train_df)\n",
    "train_df = assembler.transform(train_df)\n",
    "\n",
    "brp_model = brp.fit(train_df)\n",
    "\n",
    "# Make recommendations using KNN\n",
    "test_df = vectorAssembler.transform(test_data)\n",
    "test_df = normalizer.transform(test_df)\n",
    "test_df = test_df.join(user_factors, \"reviewer_id\", \"left\")\n",
    "test_df = test_df.selectExpr(\"reviewer_id\", \"listing_id\", \"user_features as features\")\n",
    "\n",
    "test_df = vectorSizeHint.transform(test_df)\n",
    "test_df = assembler.transform(test_df)\n",
    "\n",
    "knn_df = brp_model.approxNearestNeighbors(test_df, \"features\", 10)\n",
    "recommendations = knn_df.groupBy(\"reviewer_id\").agg(collect_list(\"listing_id\").alias(\"items\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e970804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f3597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
